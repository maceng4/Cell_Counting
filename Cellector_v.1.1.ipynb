{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage as sk\n",
    "from skimage import io\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "from skimage import data\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "#from google.colab import files \n",
    "#from google.colab import drive \n",
    "\n",
    "from PIL import Image\n",
    "from math import sqrt\n",
    "\n",
    "from io import BytesIO # For reading images from Github URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE CODE FOR IMAGES TO BE PULLED OFF GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-36b1d804893f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.__version__\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt1: does not work\n",
    "#def pull_img_from_github(url):\n",
    "#    response = requests.get(url)\n",
    "#    img = Image.open(BytesIO(response.content))\n",
    "#    plt.imshow(img)\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PVN IMAGE\n",
    "#img_pvn1 = Image.open('PVN.png') #Rutuja use this one\n",
    "img = sk.io.imread('PVN.png') #I changed this by cutting out Research folder this is for mac\n",
    "image_gray = rgb2gray(img)\n",
    "plt.imshow(image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all Blobs and Label Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFINE THIS SO IT's JUST BLOBS DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE IMAGE\n",
    "\n",
    "# Compute radii in the 3rd column.\n",
    "#blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "#threshold=.1\n",
    "blobs_log_pvn = blob_log(image_gray, min_sigma=15, max_sigma=50, num_sigma=10, threshold=.1)\n",
    "blobs_log_pvn[:, 2] = blobs_log_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_dog_pvn = blob_dog(image_gray, min_sigma=15, max_sigma=50, threshold=.1)\n",
    "blobs_dog_pvn[:, 2] = blobs_dog_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_doh_pvn = blob_doh(image_gray, min_sigma=15, max_sigma=50, threshold=.1)\n",
    "blobs_doh_pvn[:, 2] = blobs_doh_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_list = [blobs_log_pvn, blobs_dog_pvn, blobs_doh_pvn]\n",
    "colors = ['lime', 'lime', 'lime']\n",
    "titles = ['PVN LOG', 'PVN DOG', 'PVN DOH']\n",
    "sequence = zip(blobs_list, colors, titles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "for idx, (blobs, color, title) in enumerate(sequence):\n",
    "    ax[idx].set_title(title)\n",
    "    ax[idx].imshow(image_gray)\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "        ax[idx].add_patch(c)\n",
    "    ax[idx].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(blobs_dog_pvn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHANGE BELOW TO IGNORE IT AND STORE IT (EDGES AND CORNERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code finds all the blobs and puts a 70x70 pixel square around them \n",
    "# then stores them in a list \n",
    "\n",
    "bounding_box_list = []\n",
    "irregular_cells = []\n",
    "for blob in blobs_dog_pvn:\n",
    "  x, y, r, = blob \n",
    "  y = int(y.round(0))\n",
    "  x = int(x.round(0))\n",
    "  left_bound = x-70\n",
    "  right_bound = x+70\n",
    "  upper_bound = y+70\n",
    "  lower_bound = y-70\n",
    "  bounding_box = image_gray[left_bound:right_bound,lower_bound:upper_bound]\n",
    "  #Ignore this code. Just a temp solution to the images not being the same size\n",
    "  if len(bounding_box) != 140 or len(bounding_box[0]) != 140:# edge or corner\n",
    "    irregular_cells.append(bounding_box)\n",
    "  else: \n",
    "    bounding_box_list.append(bounding_box) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab one cell as an example\n",
    "plt.imshow(bounding_box_list[0])\n",
    "bounding_box_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a training set, so let's grab random items from the entire blob list \n",
    "training_images = random.sample(bounding_box_list,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = random.sample(bounding_box_list,10) # test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to label our training data, press 'c' for cell, or any other key for other.\n",
    "\n",
    "# matplob inline DOESNT WORK in colaboratory (of course), so this needs to be downloaded and run as ipynb I think... \n",
    "# in order to include the user input \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "training_labels = []\n",
    "\n",
    "\n",
    "def press(event):\n",
    "    global keypress\n",
    "    global vals\n",
    "        \n",
    "    if event.key == 'c':\n",
    "        training_labels.append('cell')\n",
    "    else: \n",
    "        training_labels.append('other')\n",
    "    \n",
    "\n",
    "    if len(training_labels) == 2:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "\n",
    "    return training_labels\n",
    "\n",
    "\n",
    "for blobss in range(10):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(training_images[blobss])\n",
    "    cid = fig.canvas.mpl_connect('key_press_event', press)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME PROCESS EXCEPT FOR TESTING DATA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "testing_labels = []\n",
    "\n",
    "\n",
    "def press(event):\n",
    "    global keypress\n",
    "    global vals\n",
    "        \n",
    "    if event.key == 'c':\n",
    "        testing_labels.append('cell')\n",
    "    else: \n",
    "        testing_labels.append('other')\n",
    "    \n",
    "\n",
    "    if len(testing_labels) == 2:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "\n",
    "    return testing_labels\n",
    "\n",
    "\n",
    "for blobss in range(10):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(test_images[blobss])\n",
    "    cid = fig.canvas.mpl_connect('key_press_event', press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "training_images = np.array(training_images)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)\n",
    "# let's check our labels\n",
    "print(test_images.shape)               \n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD IN ACCURACY / STORING INTO CSV or XCEL CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin keras code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what categories do we want to use? should be decided before selecting training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9a08a4633ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# need to set pixel values to a 0-1 scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "# need to set pixel values to a 0-1 scale\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the best layers to use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a previously saved model\n",
    "#checkpoint_path will be a path to the checkpoint from the current directory, ie 'training_test/cp.ckpt'\n",
    "def load_weights(model,checkpoint_path):\n",
    "  model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model(if model has not already been built/fitted)\n",
    "def build_model():\n",
    "  # Need to build the model, why 128??\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(140, 140)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'), # WHAT OTHER LAYERS SHOULD WE BE ADDING??\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(3)\n",
    "  ])\n",
    "  model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add training data to model\n",
    "#Params: \n",
    "#model: the model to add to\n",
    "#checkpoint_path: user defined path in case we would like to revert to this version\n",
    "#training_images: training images\n",
    "#training_labels: training labels\n",
    "#epochs: number of epochs to use\n",
    "def add_to_model(model, checkpoint_path, training_images, training_labels, num_epochs):\n",
    "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "  model.fit(training_images, \n",
    "          training_labels,  \n",
    "          epochs=num_epochs,\n",
    "          callbacks=[cp_callback]) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code that calls these above functions as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/myang/opt/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4085fb4f6065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;31m# Need to build the model, why 128??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0madd_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Checkpoints/model_v1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_images' is not defined"
     ]
    }
   ],
   "source": [
    "# OR USE THIS Proof-of-Concept\n",
    "\n",
    " # Need to build the model, why 128??\n",
    "model = build_model()\n",
    "add_to_model(model,\"Checkpoints/model_v1\",training_images,training_labels,300)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions \n",
    "\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0]) #try a prediction out [notice how test labels are not involved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0] #try a prediction out [notice how test labels are not involved]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(1))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(1), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/keras/classification\n",
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 7\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
