{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage as sk\n",
    "from skimage import io\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "from skimage import data\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "#from google.colab import files \n",
    "#from google.colab import drive \n",
    "\n",
    "from PIL import Image\n",
    "from math import sqrt\n",
    "\n",
    "import requests\n",
    "from io import BytesIO # For reading images from Github URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE CODE FOR IMAGES TO BE PULLED OFF GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x1c1b415230>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9fce0d87afb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpull_img_from_github\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/maceng4/Cellector/blob/master/PVN.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9fce0d87afb5>\u001b[0m in \u001b[0;36mpull_img_from_github\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpull_img_from_github\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myang/opt/anaconda2/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x1c1b415230>"
     ]
    }
   ],
   "source": [
    "#Attempt1: does not work\n",
    "#def pull_img_from_github(url):\n",
    "#    response = requests.get(url)\n",
    "#    img = Image.open(BytesIO(response.content))\n",
    "#    plt.imshow(img)\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PVN IMAGE\n",
    "#img_pvn1 = Image.open('my_path') #Rutuja use this one\n",
    "img = sk.io.imread(myimg) #I changed this by cutting out Research folder this is for mac\n",
    "image_gray = rgb2gray(img)\n",
    "plt.imshow(image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all Blobs and Label Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFINE THIS SO IT's JUST BLOBS DOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE IMAGE\n",
    "\n",
    "# Compute radii in the 3rd column.\n",
    "#blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "#threshold=.1\n",
    "blobs_log_pvn = blob_log(image_gray, min_sigma=15, max_sigma=50, num_sigma=10, threshold=.1)\n",
    "blobs_log_pvn[:, 2] = blobs_log_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_dog_pvn = blob_dog(image_gray, min_sigma=15, max_sigma=50, threshold=.1)\n",
    "blobs_dog_pvn[:, 2] = blobs_dog_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_doh_pvn = blob_doh(image_gray, min_sigma=15, max_sigma=50, threshold=.1)\n",
    "blobs_doh_pvn[:, 2] = blobs_doh_pvn[:, 2] * sqrt(2)\n",
    "\n",
    "blobs_list = [blobs_log_pvn, blobs_dog_pvn, blobs_doh_pvn]\n",
    "colors = ['lime', 'lime', 'lime']\n",
    "titles = ['PVN LOG', 'PVN DOG', 'PVN DOH']\n",
    "sequence = zip(blobs_list, colors, titles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "for idx, (blobs, color, title) in enumerate(sequence):\n",
    "    ax[idx].set_title(title)\n",
    "    ax[idx].imshow(image_gray)\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob\n",
    "        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n",
    "        ax[idx].add_patch(c)\n",
    "    ax[idx].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(blobs_dog_pvn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHANGE BELOW TO IGNORE IT AND STORE IT (EDGES AND CORNERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code finds all the blobs and puts a 70x70 pixel square around them \n",
    "# then stores them in a list \n",
    "\n",
    "bounding_box_list = []\n",
    "irregular_cells = []\n",
    "for blob in blobs_dog_pvn:\n",
    "  x, y, r, = blob \n",
    "  y = int(y.round(0))\n",
    "  x = int(x.round(0))\n",
    "  left_bound = x-70\n",
    "  right_bound = x+70\n",
    "  upper_bound = y+70\n",
    "  lower_bound = y-70\n",
    "  bounding_box = image_gray[left_bound:right_bound,lower_bound:upper_bound]\n",
    "  #Ignore this code. Just a temp solution to the images not being the same size\n",
    "  if len(bounding_box) != 140 or len(bounding_box[0]) != 140:# edge or corner\n",
    "    irregular_cells.append(bounding_box)\n",
    "  else: \n",
    "    bounding_box_list.append(bounding_box) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab one cell as an example\n",
    "plt.imshow(bounding_box_list[190])\n",
    "bounding_box_list[190].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a training set, so let's grab random items from the entire blob list \n",
    "training_images = random.sample(bounding_box_list,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = random.sample(bounding_box_list,10) # test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to label our training data, press 'c' for cell, or any other key for other.\n",
    "\n",
    "# matplob inline DOESNT WORK in colaboratory (of course), so this needs to be downloaded and run as ipynb I think... \n",
    "# in order to include the user input \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "training_labels = []\n",
    "\n",
    "\n",
    "def press(event):\n",
    "    global keypress\n",
    "    global vals\n",
    "        \n",
    "    if event.key == 'c':\n",
    "        training_labels.append('cell')\n",
    "    else: \n",
    "        training_labels.append('other')\n",
    "    \n",
    "\n",
    "    if len(training_labels) == 2:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "\n",
    "    return training_labels\n",
    "\n",
    "\n",
    "for blobss in range(10):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(training_images[blobss])\n",
    "    cid = fig.canvas.mpl_connect('key_press_event', press)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME PROCESS EXCEPT FOR TESTING DATA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "testing_labels = []\n",
    "\n",
    "\n",
    "def press(event):\n",
    "    global keypress\n",
    "    global vals\n",
    "        \n",
    "    if event.key == 'c':\n",
    "        testing_labels.append('cell')\n",
    "    else: \n",
    "        testing_labels.append('other')\n",
    "    \n",
    "\n",
    "    if len(testing_labels) == 2:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "\n",
    "    return testing_labels\n",
    "\n",
    "\n",
    "for blobss in range(10):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(test_images[blobss])\n",
    "    cid = fig.canvas.mpl_connect('key_press_event', press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check our labels\n",
    "print(len(test_images))               \n",
    "print(len(training_images))\n",
    "print(len(training_labels))\n",
    "print(len(testing_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD IN ACCURACY / STORING INTO CSV or XCEL CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin keras code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what categories do we want to use? should be decided before selecting training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to set pixel values to a 0-1 scale\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the best layers to use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a previously saved model\n",
    "#checkpoint_path will be a path to the checkpoint from the current directory, ie 'training_test/cp.ckpt'\n",
    "def load_weights(model,checkpoint_path):\n",
    "  model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model(if model has not already been built/fitted)\n",
    "def build_model():\n",
    "  # Need to build the model, why 128??\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Flatten(input_shape=(140, 140)),\n",
    "      keras.layers.Dense(128, activation='relu'), # WHAT OTHER LAYERS SHOULD WE BE ADDING??\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(3)\n",
    "  ])\n",
    "  model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add training data to model\n",
    "#Params: \n",
    "#model: the model to add to\n",
    "#checkpoint_path: user defined path in case we would like to revert to this version\n",
    "#training_images: training images\n",
    "#training_labels: training labels\n",
    "#epochs: number of epochs to use\n",
    "def add_to_model(model, checkpoint_path, training_images, training_labels, num_epochs):\n",
    "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "  model.fit(training_images, \n",
    "          training_labels,  \n",
    "          epochs=num_epochs,\n",
    "          callbacks=[cp_callback]) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code that calls these above functions as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR USE THIS Proof-of-Concept\n",
    "\n",
    "\n",
    " # Need to build the model, why 128??\n",
    "model = keras.Sequential([\n",
    "      keras.layers.Flatten(input_shape=(140, 140)),\n",
    "      keras.layers.Dense(128, activation='relu'),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(3)\n",
    "  ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_images, \n",
    "          training_labels,  \n",
    "          epochs=300) #might lead to overfitting if training data is small\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions \n",
    "\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0]) #try a prediction out [notice how test labels are not involved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0] #try a prediction out [notice how test labels are not involved]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(1))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(1), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/keras/classification\n",
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 7\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
